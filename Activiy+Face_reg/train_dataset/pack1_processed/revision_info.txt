arguments: src/align_dataset_mtcnn.py train_dataset/pack1 train_dataset/pack1_processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25
--------------------
tensorflow version: 2.11.0
--------------------
git hash: b'69ff1e149c0d84a123d6516ddd82970e65392608'
--------------------
b'diff --git a/src/__pycache__/facenet.cpython-37.pyc b/src/__pycache__/facenet.cpython-37.pyc\nindex 3b10b34..40bc39c 100644\nBinary files a/src/__pycache__/facenet.cpython-37.pyc and b/src/__pycache__/facenet.cpython-37.pyc differ\ndiff --git a/src/align/__pycache__/detect_face.cpython-37.pyc b/src/align/__pycache__/detect_face.cpython-37.pyc\nindex 4692c43..cfb7aed 100644\nBinary files a/src/align/__pycache__/detect_face.cpython-37.pyc and b/src/align/__pycache__/detect_face.cpython-37.pyc differ\ndiff --git a/src/face_rec_cam.py b/src/face_rec_cam.py\nindex 1a425a5..953094d 100644\n--- a/src/face_rec_cam.py\n+++ b/src/face_rec_cam.py\n@@ -18,7 +18,17 @@ import numpy as np\n import cv2\n import collections\n from sklearn.svm import SVC\n+import ctypes\n+import time\n+from pynput import keyboard\n \n+user32 = ctypes.windll.user32\n+\n+def lock_screen():\n+    user32.LockWorkStation()\n+def unlock_screen():\n+    user32 = ctypes.windll.user32\n+    user32.LockWorkStation()\n \n def main():\n     parser = argparse.ArgumentParser()\n@@ -52,9 +62,9 @@ def main():\n             facenet.load_model(FACENET_MODEL_PATH)\n \n             # Get input and output tensors\n-            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\n-            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n-            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n+            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\n+            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\n+            phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\n             embedding_size = embeddings.get_shape()[1]\n \n             pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "src/align")\n@@ -105,12 +115,16 @@ def main():\n \n \n \n-                                if best_class_probabilities > 0.8:\n+                                if best_class_probabilities > 0.7:\n                                     cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\n                                     text_x = bb[i][0]\n                                     text_y = bb[i][3] + 20\n \n                                     name = class_names[best_class_indices[0]]\n+                                    #if name != "Hung" :\n+                                     #   lock_screen()\n+                                    # elif name == "Hung" :\n+\n                                     cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n                                                 1, (255, 255, 255), thickness=1, lineType=2)\n                                     cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\n@@ -122,7 +136,6 @@ def main():\n \n                 except:\n                     pass\n-\n                 cv2.imshow(\'Face Recognition\', frame)\n                 if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n                     break'